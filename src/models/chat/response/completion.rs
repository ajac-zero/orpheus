use std::fmt::Debug;

use serde::{Deserialize, Serialize};

use crate::{Error, Result};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatCompletion {
    /// Unique identifier for the chat completion
    pub id: String,

    /// List of chat completion choices
    pub choices: Vec<ChatChoice>,

    pub provider: String,

    pub model: String,

    pub usage: super::ChatUsage,
}

impl ChatCompletion {
    pub fn message(&self) -> Result<&super::Message> {
        let message = &self
            .choices
            .iter()
            .next()
            .ok_or(Error::malformed_response(
                "Choices array in response is empty",
            ))?
            .message;

        Ok(message)
    }

    pub fn reasoning(&self) -> Result<Option<&String>> {
        Ok(self.message()?.reasoning.as_ref())
    }

    pub fn tool_calls(&self) -> Result<Option<&Vec<super::ToolCall>>> {
        Ok(self.message()?.tool_calls.as_ref())
    }

    pub fn tool_call(&self) -> Result<Option<&super::ToolCall>> {
        Ok(self.tool_calls()?.and_then(|tools| tools.first()))
    }

    pub fn into_message(self) -> Result<super::Message> {
        Ok(self
            .choices
            .into_iter()
            .next()
            .ok_or(Error::malformed_response(
                "Responses choices array is empty",
            ))?
            .message)
    }

    pub fn into_content(self) -> Result<super::Content> {
        Ok(self.into_message()?.content)
    }

    pub fn content(&self) -> Result<&super::Content> {
        Ok(&self.message()?.content)
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatChoice {
    pub index: u8,
    /// The message generated by the model
    pub message: super::Message,

    pub finish_reason: String,
}

#[cfg(test)]
mod test {
    use super::*;
    use crate::models::chat::{Content, Role};

    #[test]
    fn completion_deserialization() {
        let response_json = r#"{
               "id": "chatcmpl-abc123",
               "choices": [
                   {
                       "index": 0,
                       "message": {
                           "role": "assistant",
                           "content": "Hello! I'm doing well, thank you for asking. How can I assist you today?"
                       },
                       "finish_reason": "stop"
                   }
               ],
               "provider": "OpenAI",
               "model": "openai/gpt-4o",
               "usage": {
                   "prompt_tokens": 10,
                   "completion_tokens": 20,
                   "total_tokens": 30
               }
           }"#;

        let response: ChatCompletion = serde_json::from_str(response_json).unwrap();
        assert_eq!(response.id, "chatcmpl-abc123".to_string());

        let choices = response.choices;
        assert_eq!(choices.len(), 1);

        let message = choices[0].message.to_owned();
        assert_eq!(message.role, Role::Assistant);
        assert_eq!(
            message.content,
            Content::Simple(
                "Hello! I'm doing well, thank you for asking. How can I assist you today?"
                    .to_string()
            )
        );
    }
}

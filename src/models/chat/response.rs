use std::{
    fmt::Debug,
    io::{BufRead, BufReader},
    pin::Pin,
    task::{Context, Poll},
};

use futures_lite::Stream;
use reqwest::blocking;
use serde::{Deserialize, Serialize};

use super::Message;
use crate::{Error, Result};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatCompletion {
    /// Unique identifier for the chat completion
    pub id: String,

    /// List of chat completion choices
    pub choices: Vec<ChatChoice>,

    pub provider: String,

    pub model: String,
}

impl ChatCompletion {
    pub fn message(&self) -> Result<&super::Message> {
        let message = &self
            .choices
            .iter()
            .next()
            .ok_or(Error::malformed_response(
                "Choices array in response is empty",
            ))?
            .message;

        Ok(message)
    }

    pub fn reasoning(&self) -> Result<Option<&String>> {
        Ok(self.message()?.reasoning.as_ref())
    }

    pub fn tool_calls(&self) -> Result<Option<&Vec<super::ToolCall>>> {
        Ok(self.message()?.tool_calls.as_ref())
    }

    pub fn tool_call(&self) -> Result<Option<&super::ToolCall>> {
        Ok(self.tool_calls()?.and_then(|tools| tools.first()))
    }

    pub fn into_message(self) -> Result<super::Message> {
        Ok(self
            .choices
            .into_iter()
            .next()
            .ok_or(Error::malformed_response(
                "Responses choices array is empty",
            ))?
            .message)
    }

    pub fn into_content(self) -> Result<super::Content> {
        Ok(self.into_message()?.content)
    }

    pub fn content(&self) -> Result<&super::Content> {
        Ok(&self.message()?.content)
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatChoice {
    /// The message generated by the model
    pub message: Message,
}

#[serde_with::skip_serializing_none]
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatStreamChunk {
    /// Unique identifier for the chat completion
    pub id: String,

    /// The provider of the model
    pub provider: Option<String>,

    /// The model used for the completion
    pub model: Option<String>,

    /// The object type (always "chat.completion.chunk" for streaming)
    pub object: String,

    /// Unix timestamp of when the completion was created
    pub created: i64,

    /// List of streaming choices
    pub choices: Vec<ChatStreamChoice>,

    /// System fingerprint for the response
    pub system_fingerprint: Option<String>,

    /// Usage statistics (only present in the final chunk)
    pub usage: Option<ChatUsage>,
}

impl ChatStreamChunk {
    pub fn delta(&self) -> Result<&super::Message> {
        let message = &self
            .choices
            .iter()
            .next()
            .ok_or(Error::malformed_response(
                "Choices array in response is empty",
            ))?
            .delta;

        Ok(message)
    }

    pub fn into_delta(self) -> Result<super::Message> {
        let message = self
            .choices
            .into_iter()
            .next()
            .ok_or(Error::malformed_response(
                "Choices array in response is empty",
            ))?
            .delta;

        Ok(message)
    }

    pub fn into_content(self) -> Result<super::Content> {
        Ok(self.into_delta()?.content)
    }

    pub fn content(&self) -> Result<&super::Content> {
        Ok(&self.delta()?.content)
    }

    pub fn reasoning(&self) -> Result<Option<&String>> {
        Ok(self.delta()?.reasoning.as_ref())
    }
}

#[serde_with::skip_serializing_none]
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatStreamChoice {
    /// The index of the choice
    pub index: u32,

    /// The delta containing incremental message content
    pub delta: Message,

    /// The reason the completion finished
    pub finish_reason: Option<String>,

    /// The native finish reason from the provider
    pub native_finish_reason: Option<String>,

    /// Log probabilities for the choice
    pub logprobs: Option<serde_json::Value>,
}

#[serde_with::skip_serializing_none]
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatUsage {
    /// Number of tokens in the prompt
    pub prompt_tokens: u32,

    /// Number of tokens in the completion
    pub completion_tokens: u32,

    /// Total number of tokens used
    pub total_tokens: u32,

    /// Detailed prompt token information
    pub prompt_tokens_details: Option<PromptTokensDetails>,

    /// Detailed completion token information
    pub completion_tokens_details: Option<CompletionTokensDetails>,
}

#[serde_with::skip_serializing_none]
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PromptTokensDetails {
    /// Number of cached tokens in the prompt
    pub cached_tokens: u32,
}

#[serde_with::skip_serializing_none]
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CompletionTokensDetails {
    /// Number of reasoning tokens in the completion
    pub reasoning_tokens: u32,
}

#[derive(Debug)]
pub struct ChatStream(BufReader<blocking::Response>);

impl From<blocking::Response> for ChatStream {
    fn from(value: blocking::Response) -> Self {
        Self::new(value)
    }
}

impl ChatStream {
    pub fn new(response: reqwest::blocking::Response) -> Self {
        let reader = BufReader::new(response);
        Self(reader)
    }
}

impl Iterator for ChatStream {
    type Item = Result<ChatStreamChunk>;

    fn next(&mut self) -> Option<Self::Item> {
        let mut line = String::new();

        let item = loop {
            line.clear();

            let bytes_read = match self.0.read_line(&mut line) {
                Ok(bytes_read) => bytes_read,
                Err(e) => break Err(Error::io(e)),
            };

            if bytes_read == 0 {
                return None; // Stream is empty
            }

            let line = line.trim();
            if line.is_empty() || line.starts_with(":") {
                continue; // Skip comments/keepalives
            }

            if !line.starts_with("data: ") {
                break Err(Error::invalid_sse(line));
            }

            let json_str = &line[6..]; // Remove "data: " prefix and trailing whitespace

            if json_str == "[DONE]" {
                return None; // Stream is explicitly over
            }

            let chunk = match serde_json::from_str(json_str) {
                Ok(chunk) => chunk,
                Err(e) => break Err(Error::serde(e)),
            };

            break Ok(chunk);
        };

        Some(item)
    }
}

pub struct AsyncStream {
    stream: Pin<Box<dyn Stream<Item = Result<bytes::Bytes, reqwest::Error>> + Send>>,
    buffer: Vec<u8>,
}

impl From<reqwest::Response> for AsyncStream {
    fn from(value: reqwest::Response) -> Self {
        Self::new(value)
    }
}

impl AsyncStream {
    pub fn new(response: reqwest::Response) -> Self {
        let stream = Box::pin(response.bytes_stream());
        Self {
            stream,
            buffer: Vec::new(), // Initialize as Vec<u8>
        }
    }
}

impl Stream for AsyncStream {
    type Item = Result<ChatStreamChunk>;

    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {
        let this = self.get_mut();

        let result = loop {
            // First, try to extract a complete line from existing buffer
            if let Some(line_bytes) = extract_line(&mut this.buffer) {
                let line = String::from_utf8_lossy(&line_bytes);
                let line = line.trim();

                // Skip empty lines and comments
                if line.is_empty() || line.starts_with(":") {
                    continue;
                }

                // Validate SSE format
                if !line.starts_with("data: ") {
                    break Some(Err(Error::invalid_sse(line)));
                }

                let json_str = &line[6..]; // Remove "data: " prefix
                if json_str == "[DONE]" {
                    break None;
                }

                break Some(serde_json::from_str(json_str).map_err(Error::serde));
            }

            // No complete line found, need more data from stream
            match this.stream.as_mut().poll_next(cx) {
                Poll::Pending => return Poll::Pending,
                Poll::Ready(None) => {
                    // Stream ended - check if we have remaining data
                    if this.buffer.is_empty() {
                        return Poll::Ready(None);
                    } else {
                        // Process final incomplete line
                        let line_clone = this.buffer.clone();
                        let line = String::from_utf8_lossy(&line_clone);
                        this.buffer.clear();
                        let line = line.trim();

                        if line.is_empty() || line.starts_with(":") {
                            return Poll::Ready(None);
                        }

                        if !line.starts_with("data: ") {
                            return Poll::Ready(Some(Err(Error::invalid_sse(line))));
                        }

                        let json_str = &line[6..];
                        if json_str == "[DONE]" {
                            return Poll::Ready(None);
                        }

                        match serde_json::from_str::<ChatStreamChunk>(json_str) {
                            Ok(chunk) => return Poll::Ready(Some(Ok(chunk))),
                            Err(e) => {
                                return Poll::Ready(Some(Err(Error::serde(e))));
                            }
                        }
                    }
                }
                Poll::Ready(Some(item)) => match item {
                    Ok(bytes) => this.buffer.extend_from_slice(&bytes),
                    Err(e) => break Some(Err(Error::http(e))),
                },
            }
        };

        Poll::Ready(result)
    }
}

// Helper function to extract a complete line from buffer
fn extract_line(buffer: &mut Vec<u8>) -> Option<Vec<u8>> {
    // Look for newline
    if let Some(newline_pos) = buffer.iter().position(|&b| b == b'\n') {
        // Extract the line including the newline
        let mut line: Vec<u8> = buffer.drain(0..=newline_pos).collect();

        // Remove the newline
        line.pop();

        // Remove carriage return if present (for \r\n line endings)
        if line.last() == Some(&b'\r') {
            line.pop();
        }

        Some(line)
    } else {
        None
    }
}

impl Debug for AsyncStream {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("AsyncStream").finish()
    }
}

#[cfg(test)]
mod test {
    use super::{
        super::{Content, Role},
        *,
    };

    #[tokio::test]
    async fn test_chat_response_deserialization() {
        let response_json = r#"{
                "id": "chatcmpl-abc123",
                "choices": [
                    {
                        "message": {
                            "role": "assistant",
                            "content": "Hello! I'm doing well, thank you for asking. How can I assist you today?"
                        }
                    }
                ],
                "provider": "OpenAI",
                "model": "openai/gpt-4o"
            }"#;

        let response: ChatCompletion = serde_json::from_str(response_json).unwrap();
        assert_eq!(response.id, "chatcmpl-abc123".to_string());

        let choices = response.choices;
        assert_eq!(choices.len(), 1);

        let message = choices[0].message.to_owned();
        assert_eq!(message.role, Role::Assistant);
        assert_eq!(
            message.content,
            Content::Simple(
                "Hello! I'm doing well, thank you for asking. How can I assist you today?"
                    .to_string()
            )
        );
    }

    #[tokio::test]
    async fn test_chat_stream_chunk_deserialization() {
        let chunk_json = r#"{
            "id": "gen-1749454386-VRY5G3UxpEJ8uAfP2MnL",
            "provider": "OpenAI",
            "model": "openai/gpt-4o",
            "object": "chat.completion.chunk",
            "created": 1749454386,
            "choices": [
                {
                    "index": 0,
                    "delta": {
                        "role": "assistant",
                        "content": "Hello"
                    },
                    "finish_reason": null,
                    "native_finish_reason": null,
                    "logprobs": null
                }
            ],
            "system_fingerprint": "fp_07871e2ad8"
        }"#;

        let chunk: ChatStreamChunk = serde_json::from_str(chunk_json).unwrap();
        assert_eq!(chunk.id, "gen-1749454386-VRY5G3UxpEJ8uAfP2MnL");
        assert_eq!(chunk.provider, Some("OpenAI".to_string()));
        assert_eq!(chunk.model, Some("openai/gpt-4o".to_string()));
        assert_eq!(chunk.object, "chat.completion.chunk");
        assert_eq!(chunk.created, 1749454386);
        assert_eq!(chunk.choices.len(), 1);

        let choice = &chunk.choices[0];
        assert_eq!(choice.index, 0);
        assert_eq!(choice.delta.role, Role::Assistant);
        assert_eq!(choice.delta.content, "Hello".into());
        assert_eq!(choice.finish_reason, None);
    }

    #[tokio::test]
    async fn test_chat_stream_chunk_with_usage() {
        let chunk_json = r#"{
            "id": "gen-1749454386-VRY5G3UxpEJ8uAfP2MnL",
            "provider": "OpenAI",
            "model": "openai/gpt-4o",
            "object": "chat.completion.chunk",
            "created": 1749454386,
            "choices": [
                {
                    "index": 0,
                    "delta": {
                        "role": "assistant",
                        "content": ""
                    },
                    "finish_reason": null,
                    "native_finish_reason": null,
                    "logprobs": null
                }
            ],
            "usage": {
                "prompt_tokens": 8,
                "completion_tokens": 9,
                "total_tokens": 17,
                "prompt_tokens_details": {
                    "cached_tokens": 0
                },
                "completion_tokens_details": {
                    "reasoning_tokens": 0
                }
            }
        }"#;

        let chunk: ChatStreamChunk = serde_json::from_str(chunk_json).unwrap();
        assert!(chunk.usage.is_some());

        let usage = chunk.usage.unwrap();
        assert_eq!(usage.prompt_tokens, 8);
        assert_eq!(usage.completion_tokens, 9);
        assert_eq!(usage.total_tokens, 17);
        assert!(usage.prompt_tokens_details.is_some());
        assert!(usage.completion_tokens_details.is_some());
    }
}

use std::io::{BufRead, BufReader};
use std::task::{Context, Poll};
use std::{fmt::Debug, pin::Pin};

use either::Either;
use futures_lite::Stream;
use reqwest::blocking;
use serde::{Deserialize, Serialize};

use crate::exceptions::OrpheusError;

use super::ChatMessage;

#[serde_with::skip_serializing_none]
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatCompletion {
    /// Unique identifier for the chat completion
    pub id: Option<String>,

    /// List of chat completion choices
    pub choices: Option<Vec<ChatChoice>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatChoice {
    /// The message generated by the model
    pub message: Option<ChatMessage>,
}

#[serde_with::skip_serializing_none]
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatStreamChunk {
    /// Unique identifier for the chat completion
    pub id: String,

    /// The provider of the model
    pub provider: Option<String>,

    /// The model used for the completion
    pub model: Option<String>,

    /// The object type (always "chat.completion.chunk" for streaming)
    pub object: String,

    /// Unix timestamp of when the completion was created
    pub created: i64,

    /// List of streaming choices
    pub choices: Vec<ChatStreamChoice>,

    /// System fingerprint for the response
    pub system_fingerprint: Option<String>,

    /// Usage statistics (only present in the final chunk)
    pub usage: Option<ChatUsage>,
}

impl From<ChatStreamChunk> for String {
    fn from(value: ChatStreamChunk) -> Self {
        let content = value.choices.first().unwrap().clone().delta.content;

        if let Some(content) = content {
            content
        } else {
            "".to_string()
        }
    }
}

#[serde_with::skip_serializing_none]
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatStreamChoice {
    /// The index of the choice
    pub index: u32,

    /// The delta containing incremental message content
    pub delta: ChatStreamDelta,

    /// The reason the completion finished
    pub finish_reason: Option<String>,

    /// The native finish reason from the provider
    pub native_finish_reason: Option<String>,

    /// Log probabilities for the choice
    pub logprobs: Option<serde_json::Value>,
}

#[serde_with::skip_serializing_none]
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatStreamDelta {
    /// The role of the message (typically "assistant" for responses)
    pub role: Option<String>,

    /// The incremental content of the message
    pub content: Option<String>,
}

#[serde_with::skip_serializing_none]
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatUsage {
    /// Number of tokens in the prompt
    pub prompt_tokens: u32,

    /// Number of tokens in the completion
    pub completion_tokens: u32,

    /// Total number of tokens used
    pub total_tokens: u32,

    /// Detailed prompt token information
    pub prompt_tokens_details: Option<PromptTokensDetails>,

    /// Detailed completion token information
    pub completion_tokens_details: Option<CompletionTokensDetails>,
}

#[serde_with::skip_serializing_none]
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PromptTokensDetails {
    /// Number of cached tokens in the prompt
    pub cached_tokens: u32,
}

#[serde_with::skip_serializing_none]
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CompletionTokensDetails {
    /// Number of reasoning tokens in the completion
    pub reasoning_tokens: u32,
}

#[derive(Debug)]
pub struct ChatStream(BufReader<blocking::Response>);

impl From<blocking::Response> for ChatStream {
    fn from(value: blocking::Response) -> Self {
        Self::new(value)
    }
}

impl ChatStream {
    pub fn new(response: reqwest::blocking::Response) -> Self {
        let reader = BufReader::new(response);
        Self(reader)
    }

    pub fn next(&mut self) -> Result<Option<ChatStreamChunk>, OrpheusError> {
        let mut line = String::new();

        loop {
            line.clear();
            match self.0.read_line(&mut line)? {
                0 => break Ok(None),
                _ => {
                    let line = line.trim();
                    if line.is_empty() || line.starts_with(":") {
                        continue;
                    }

                    assert!(line.starts_with("data: "), "Invalid SSE line: {}", line);

                    let json_str = &line[6..]; // Remove "data: " prefix and trailing whitespace

                    if json_str == "[DONE]" {
                        break Ok(None);
                    }

                    return Ok(Some(serde_json::from_str::<ChatStreamChunk>(json_str)?));
                }
            }
        }
    }
}

pub struct AsyncStream {
    stream: Pin<Box<dyn Stream<Item = Result<bytes::Bytes, reqwest::Error>> + Send>>,
    buffer: Vec<u8>,
}

impl From<reqwest::Response> for AsyncStream {
    fn from(value: reqwest::Response) -> Self {
        Self::new(value)
    }
}

impl AsyncStream {
    pub fn new(response: reqwest::Response) -> Self {
        let stream = Box::pin(response.bytes_stream());
        Self {
            stream,
            buffer: Vec::new(), // Initialize as Vec<u8>
        }
    }
}

impl Stream for AsyncStream {
    type Item = Result<ChatStreamChunk, OrpheusError>;

    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {
        let this = self.get_mut();

        let result = loop {
            // First, try to extract a complete line from existing buffer
            if let Some(line_bytes) = extract_line(&mut this.buffer) {
                let line = String::from_utf8_lossy(&line_bytes);
                let line = line.trim();

                // Skip empty lines and comments
                if line.is_empty() || line.starts_with(":") {
                    continue;
                }

                // Validate SSE format
                if !line.starts_with("data: ") {
                    break Some(Err(OrpheusError::Anyhow(format!(
                        "Invalid SSE line: {:?}",
                        line
                    ))));
                }

                let json_str = &line[6..]; // Remove "data: " prefix
                if json_str == "[DONE]" {
                    break None;
                }

                // Parse JSON - handle the Result properly
                match serde_json::from_str::<ChatStreamChunk>(json_str) {
                    Ok(chunk) => break Some(Ok(chunk)),
                    Err(e) => break Some(Err(OrpheusError::Anyhow(e.to_string()))),
                }
            }

            // No complete line found, need more data from stream
            match this.stream.as_mut().poll_next(cx) {
                Poll::Pending => return Poll::Pending,
                Poll::Ready(None) => {
                    // Stream ended - check if we have remaining data
                    if this.buffer.is_empty() {
                        return Poll::Ready(None);
                    } else {
                        // Process final incomplete line
                        let line_clone = this.buffer.clone();
                        let line = String::from_utf8_lossy(&line_clone);
                        this.buffer.clear();
                        let line = line.trim();

                        if line.is_empty() || line.starts_with(":") {
                            return Poll::Ready(None);
                        }

                        if !line.starts_with("data: ") {
                            return Poll::Ready(Some(Err(OrpheusError::Anyhow(format!(
                                "Invalid SSE line: {:?}",
                                line
                            )))));
                        }

                        let json_str = &line[6..];
                        if json_str == "[DONE]" {
                            return Poll::Ready(None);
                        }

                        match serde_json::from_str::<ChatStreamChunk>(json_str) {
                            Ok(chunk) => return Poll::Ready(Some(Ok(chunk))),
                            Err(e) => {
                                return Poll::Ready(Some(Err(OrpheusError::Anyhow(e.to_string()))));
                            }
                        }
                    }
                }
                Poll::Ready(Some(item)) => match item {
                    Ok(bytes) => this.buffer.extend_from_slice(&bytes),
                    Err(e) => break Some(Err(OrpheusError::Anyhow(e.to_string()))),
                },
            }
        };

        Poll::Ready(result)
    }
}

// Helper function to extract a complete line from buffer
fn extract_line(buffer: &mut Vec<u8>) -> Option<Vec<u8>> {
    // Look for newline
    if let Some(newline_pos) = buffer.iter().position(|&b| b == b'\n') {
        // Extract the line including the newline
        let mut line: Vec<u8> = buffer.drain(0..=newline_pos).collect();

        // Remove the newline
        line.pop();

        // Remove carriage return if present (for \r\n line endings)
        if line.last() == Some(&b'\r') {
            line.pop();
        }

        Some(line)
    } else {
        None
    }
}

impl Debug for AsyncStream {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("AsyncStream").finish()
    }
}

pub type ChatResponse = Either<ChatCompletion, ChatStream>;
pub type AsyncChatResponse = Either<ChatCompletion, AsyncStream>;

#[cfg(test)]
mod test {
    use super::super::{Content, MessageRole};
    use super::*;

    #[tokio::test]
    async fn test_chat_response_deserialization() {
        let response_json = r#"{
                "id": "chatcmpl-abc123",
                "choices": [
                    {
                        "message": {
                            "role": "assistant",
                            "content": "Hello! I'm doing well, thank you for asking. How can I assist you today?"
                        }
                    }
                ]
            }"#;

        let response: ChatCompletion = serde_json::from_str(response_json).unwrap();
        assert_eq!(response.id, Some("chatcmpl-abc123".to_string()));
        assert!(response.choices.is_some());

        let choices = response.choices.unwrap();
        assert_eq!(choices.len(), 1);

        let message = choices[0].message.as_ref().unwrap();
        assert_eq!(message.role, MessageRole::Assistant);
        assert_eq!(
            message.content,
            Content::Simple(
                "Hello! I'm doing well, thank you for asking. How can I assist you today?"
                    .to_string()
            )
        );
    }

    #[tokio::test]
    async fn test_chat_stream_chunk_deserialization() {
        let chunk_json = r#"{
            "id": "gen-1749454386-VRY5G3UxpEJ8uAfP2MnL",
            "provider": "OpenAI",
            "model": "openai/gpt-4o",
            "object": "chat.completion.chunk",
            "created": 1749454386,
            "choices": [
                {
                    "index": 0,
                    "delta": {
                        "role": "assistant",
                        "content": "Hello"
                    },
                    "finish_reason": null,
                    "native_finish_reason": null,
                    "logprobs": null
                }
            ],
            "system_fingerprint": "fp_07871e2ad8"
        }"#;

        let chunk: ChatStreamChunk = serde_json::from_str(chunk_json).unwrap();
        assert_eq!(chunk.id, "gen-1749454386-VRY5G3UxpEJ8uAfP2MnL");
        assert_eq!(chunk.provider, Some("OpenAI".to_string()));
        assert_eq!(chunk.model, Some("openai/gpt-4o".to_string()));
        assert_eq!(chunk.object, "chat.completion.chunk");
        assert_eq!(chunk.created, 1749454386);
        assert_eq!(chunk.choices.len(), 1);

        let choice = &chunk.choices[0];
        assert_eq!(choice.index, 0);
        assert_eq!(choice.delta.role, Some("assistant".to_string()));
        assert_eq!(choice.delta.content, Some("Hello".to_string()));
        assert_eq!(choice.finish_reason, None);
    }

    #[tokio::test]
    async fn test_chat_stream_chunk_with_usage() {
        let chunk_json = r#"{
            "id": "gen-1749454386-VRY5G3UxpEJ8uAfP2MnL",
            "provider": "OpenAI",
            "model": "openai/gpt-4o",
            "object": "chat.completion.chunk",
            "created": 1749454386,
            "choices": [
                {
                    "index": 0,
                    "delta": {
                        "role": "assistant",
                        "content": ""
                    },
                    "finish_reason": null,
                    "native_finish_reason": null,
                    "logprobs": null
                }
            ],
            "usage": {
                "prompt_tokens": 8,
                "completion_tokens": 9,
                "total_tokens": 17,
                "prompt_tokens_details": {
                    "cached_tokens": 0
                },
                "completion_tokens_details": {
                    "reasoning_tokens": 0
                }
            }
        }"#;

        let chunk: ChatStreamChunk = serde_json::from_str(chunk_json).unwrap();
        assert!(chunk.usage.is_some());

        let usage = chunk.usage.unwrap();
        assert_eq!(usage.prompt_tokens, 8);
        assert_eq!(usage.completion_tokens, 9);
        assert_eq!(usage.total_tokens, 17);
        assert!(usage.prompt_tokens_details.is_some());
        assert!(usage.completion_tokens_details.is_some());
    }
}
